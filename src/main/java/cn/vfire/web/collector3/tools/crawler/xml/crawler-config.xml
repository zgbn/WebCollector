<?xml version="1.0" encoding="utf-8"?>
<crawlerconfigs xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://xmlschema.vfire.cn/xsd/crawlerconfigs"
	xsi:schemaLocation="http://xmlschema.vfire.cn/xsd/crawlerconfigs crawler-config-3.0.xsd">

	<!-- 0个 多个 -->
	<formatclass id="DemoDataFormat"
		class="cn.vfire.web.collector.tools.crawlerconfigxml.format.impl.DefaultDataFormat"></formatclass>

	<event id="ssss" class="cn.vfire.web.collector3.crawler.event.DefaultCrawlerEvent" />
	<event id="ssss1" class="cn.vfire.web.collector3.crawler.event.DefaultCrawlerEvent" />

	<!-- 0-1个 -->
	<proxyip id="proxyipid" class="cn.vfire.web.collector3.tools.crawler.proxyip.impl.DefaultProxyIpPool" />


	<!-- 0个 多个 -->
	<outfile id="outfile" zip="Gzip">
		<prefix>suffix</prefix>
		<suffix>.${sn}.txt</suffix>
		<name>${selecter.selecter2.selecter1}</name>
		<path>/${selecter.selecter2.selecter1}/</path>
	</outfile>

	<!-- 0-多个 -->
	<outdata id="outdataid">
		<formatclass ref="DemoDataFormat" />
		<outfile ref="outfile" />
	</outdata>

	<!-- 1个 -->
	<crawlerconfig id="crawlerJob" depth="1" isproxy="false" maxexecutecount="5" retry="1"
		topnum="-1" maxthreads="50" keepalivetime="5" threads="5">

		<name>采集任务</name>
		<description>采集描述</description>

		<seedurl>http://www.biquge.la/book/5313/</seedurl>

		<regexrules>
			<regex>http://www.biquge.la/book/[0-9]+/[0-9]+.html</regex>
		</regexrules>
		<unregexrules>
			<regex>aaa</regex>
			<regex>bbb</regex>
			<regex>ccc</regex>
		</unregexrules>

		<event ref="ssss" />

		<snapshot runtime="0" exceptioncount="0" count="0">
			<snapshotinfo class="cn.vfire.web.collector3.crawler.snapshot.DefaultCatchSnapshotInfo" />
		</snapshot>

		<datamode id="datamode1" selecter="selecter">
			<urls>
				<regex>aaa</regex>
				<regex>bbb</regex>
				<regex>ccc</regex>
			</urls>
			<outdata ref="outdataid" />
			<node key="name1" value="123456" />
			<node key="data" selecter="selecter2">
				<node key="key1" selecter="selecter.selecter2.selecter1" attr="id" />
				<node key="key2" selecter="selecter.selecter2.selecter2"></node>
				<node key="key3" selecter="selecter.selecter2.selecter3"></node>
				<list key="data" selecter="selecter.selecter2.selecter4">
					<node selecter="selecter.selecter2.selecter3.1"></node>
					<node selecter="selecter.selecter2.selecter3.2"></node>
					<node selecter="selecter.selecter2.selecter3.3"></node>
				</list>
			</node>
		</datamode>

		<datamode id="datamode2" selecter="selecter" label="小说">
			<urls>
				<regex>aaa2</regex>
				<regex>bbb2</regex>
				<regex>ccc2</regex>
			</urls>
			<outdata ref="outdataid" />
			<node key="name1" value="123456" label="标题" />
			<node key="data" selecter="selecter2" label="章节">
				<node key="key1" selecter="selecter.selecter2.selecter1" label="A"></node>
				<node key="key2" selecter="selecter.selecter2.selecter2" label="B"></node>
				<node key="key3" selecter="selecter.selecter2.selecter3" label="C"></node>
				<list key="data" label="D" value="">
					<node selecter="selecter.selecter2.selecter3.1"></node>
					<node selecter="selecter.selecter2.selecter3.2"></node>
					<node selecter="selecter.selecter2.selecter3.3"></node>
				</list>
			</node>
		</datamode>

	</crawlerconfig>







</crawlerconfigs>